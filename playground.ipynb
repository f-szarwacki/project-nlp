{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQv_2KFChkpp",
        "outputId": "f70ff1a7-6158-4b32-faa4-cbcfe616d143"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XBMFF4u2Z_VE",
        "outputId": "cd390fe8-ee9d-4323-a5e6-cc51ba15519c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  project-nlp-update-transformers-lib.zip\n",
            "301f47f67f9be67be1bd9aafba1827e54d162c55\n",
            "   creating: project-nlp-update-transformers-lib/\n",
            "   creating: project-nlp-update-transformers-lib/.github/\n",
            "   creating: project-nlp-update-transformers-lib/.github/workflows/\n",
            "  inflating: project-nlp-update-transformers-lib/.github/workflows/stale.yml  \n",
            "  inflating: project-nlp-update-transformers-lib/.gitignore  \n",
            "  inflating: project-nlp-update-transformers-lib/LICENSE  \n",
            "  inflating: project-nlp-update-transformers-lib/README.md  \n",
            "   creating: project-nlp-update-transformers-lib/SentEval/\n",
            "  inflating: project-nlp-update-transformers-lib/SentEval/.gitignore  \n",
            "  inflating: project-nlp-update-transformers-lib/SentEval/LICENSE  \n",
            "  inflating: project-nlp-update-transformers-lib/SentEval/README.md  \n",
            "   creating: project-nlp-update-transformers-lib/SentEval/data/\n",
            "   creating: project-nlp-update-transformers-lib/SentEval/data/downstream/\n",
            "  inflating: project-nlp-update-transformers-lib/SentEval/data/downstream/download_dataset.sh  \n",
            "   creating: project-nlp-update-transformers-lib/SentEval/examples/\n",
            "  inflating: project-nlp-update-transformers-lib/SentEval/examples/bow.py  \n",
            "  inflating: project-nlp-update-transformers-lib/SentEval/examples/gensen.py  \n",
            "  inflating: project-nlp-update-transformers-lib/SentEval/examples/googleuse.py  \n",
            "  inflating: project-nlp-update-transformers-lib/SentEval/examples/infersent.py  \n",
            "  inflating: project-nlp-update-transformers-lib/SentEval/examples/models.py  \n",
            "  inflating: project-nlp-update-transformers-lib/SentEval/examples/skipthought.py  \n",
            "   creating: project-nlp-update-transformers-lib/SentEval/senteval/\n",
            "  inflating: project-nlp-update-transformers-lib/SentEval/senteval/__init__.py  \n",
            "  inflating: project-nlp-update-transformers-lib/SentEval/senteval/binary.py  \n",
            "  inflating: project-nlp-update-transformers-lib/SentEval/senteval/engine.py  \n",
            "  inflating: project-nlp-update-transformers-lib/SentEval/senteval/mrpc.py  \n",
            "  inflating: project-nlp-update-transformers-lib/SentEval/senteval/probing.py  \n",
            "  inflating: project-nlp-update-transformers-lib/SentEval/senteval/rank.py  \n",
            "  inflating: project-nlp-update-transformers-lib/SentEval/senteval/sick.py  \n",
            "  inflating: project-nlp-update-transformers-lib/SentEval/senteval/snli.py  \n",
            "  inflating: project-nlp-update-transformers-lib/SentEval/senteval/sst.py  \n",
            "  inflating: project-nlp-update-transformers-lib/SentEval/senteval/sts.py  \n",
            "   creating: project-nlp-update-transformers-lib/SentEval/senteval/tools/\n",
            " extracting: project-nlp-update-transformers-lib/SentEval/senteval/tools/__init__.py  \n",
            "  inflating: project-nlp-update-transformers-lib/SentEval/senteval/tools/classifier.py  \n",
            "  inflating: project-nlp-update-transformers-lib/SentEval/senteval/tools/ranking.py  \n",
            "  inflating: project-nlp-update-transformers-lib/SentEval/senteval/tools/relatedness.py  \n",
            "  inflating: project-nlp-update-transformers-lib/SentEval/senteval/tools/validation.py  \n",
            "  inflating: project-nlp-update-transformers-lib/SentEval/senteval/trec.py  \n",
            "  inflating: project-nlp-update-transformers-lib/SentEval/senteval/utils.py  \n",
            "  inflating: project-nlp-update-transformers-lib/SentEval/setup.py  \n",
            "   creating: project-nlp-update-transformers-lib/data/\n",
            "  inflating: project-nlp-update-transformers-lib/data/download_nli.sh  \n",
            "  inflating: project-nlp-update-transformers-lib/data/download_uniprot.sh  \n",
            "  inflating: project-nlp-update-transformers-lib/data/download_wiki.sh  \n",
            "   creating: project-nlp-update-transformers-lib/demo/\n",
            "  inflating: project-nlp-update-transformers-lib/demo/README.md  \n",
            "  inflating: project-nlp-update-transformers-lib/demo/flaskdemo.py  \n",
            "  inflating: project-nlp-update-transformers-lib/demo/gradiodemo.py  \n",
            "  inflating: project-nlp-update-transformers-lib/demo/run_demo_example.sh  \n",
            "   creating: project-nlp-update-transformers-lib/demo/static/\n",
            "  inflating: project-nlp-update-transformers-lib/demo/static/example_query.txt  \n",
            "  inflating: project-nlp-update-transformers-lib/demo/static/example_sentence.txt  \n",
            "   creating: project-nlp-update-transformers-lib/demo/static/files/\n",
            "  inflating: project-nlp-update-transformers-lib/demo/static/files/all.js  \n",
            "  inflating: project-nlp-update-transformers-lib/demo/static/files/bootstrap.min.js  \n",
            "  inflating: project-nlp-update-transformers-lib/demo/static/files/favicon.ico  \n",
            "  inflating: project-nlp-update-transformers-lib/demo/static/files/jquery-3.3.1.min.js  \n",
            "  inflating: project-nlp-update-transformers-lib/demo/static/files/plogo.png  \n",
            "  inflating: project-nlp-update-transformers-lib/demo/static/files/popper.min.js  \n",
            "  inflating: project-nlp-update-transformers-lib/demo/static/files/style.css  \n",
            "  inflating: project-nlp-update-transformers-lib/demo/static/index.html  \n",
            "  inflating: project-nlp-update-transformers-lib/evaluation.py  \n",
            "   creating: project-nlp-update-transformers-lib/figure/\n",
            "  inflating: project-nlp-update-transformers-lib/figure/demo.gif  \n",
            "  inflating: project-nlp-update-transformers-lib/figure/model.png  \n",
            "  inflating: project-nlp-update-transformers-lib/playground.ipynb  \n",
            "  inflating: project-nlp-update-transformers-lib/requirements.txt  \n",
            "  inflating: project-nlp-update-transformers-lib/run_sup_example.sh  \n",
            "  inflating: project-nlp-update-transformers-lib/run_unsup_example.sh  \n",
            "  inflating: project-nlp-update-transformers-lib/setup.py  \n",
            "   creating: project-nlp-update-transformers-lib/simcse/\n",
            " extracting: project-nlp-update-transformers-lib/simcse/__init__.py  \n",
            "  inflating: project-nlp-update-transformers-lib/simcse/models.py  \n",
            "  inflating: project-nlp-update-transformers-lib/simcse/tool.py  \n",
            "  inflating: project-nlp-update-transformers-lib/simcse/trainers.py  \n",
            "  inflating: project-nlp-update-transformers-lib/simcse_to_huggingface.py  \n",
            "   creating: project-nlp-update-transformers-lib/slides/\n",
            "  inflating: project-nlp-update-transformers-lib/slides/emnlp2021_slides.pdf  \n",
            "  inflating: project-nlp-update-transformers-lib/train.py  \n"
          ]
        }
      ],
      "source": [
        "!unzip project-nlp-update-transformers-lib.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaBZpd20bOiN",
        "outputId": "90d2bf0d-bfe9-40a3-90cf-40583316edb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/project-nlp-update-transformers-lib\n"
          ]
        }
      ],
      "source": [
        "%cd project-nlp-update-transformers-lib/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Rpcx-LFfxCw",
        "outputId": "87ccb4c3-d092-4d8c-cb9f-a9959cea0a6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers==4.30.2 (from -r requirements.txt (line 1))\n",
            "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (1.10.1)\n",
            "Collecting datasets (from -r requirements.txt (line 3))\n",
            "  Downloading datasets-2.13.1-py3-none-any.whl (486 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.2/486.2 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (1.5.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (1.2.2)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (0.7.2)\n",
            "Collecting gradio (from -r requirements.txt (line 7))\n",
            "  Downloading gradio-3.35.2-py3-none-any.whl (19.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (2.0.1+cu118)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (67.7.2)\n",
            "Collecting tape_proteins==0.5 (from -r requirements.txt (line 10))\n",
            "  Downloading tape_proteins-0.5-py3-none-any.whl (68 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.9/68.9 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate (from -r requirements.txt (line 11))\n",
            "  Downloading accelerate-0.20.3-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.6/227.6 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.2->-r requirements.txt (line 1)) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers==4.30.2->-r requirements.txt (line 1))\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.2->-r requirements.txt (line 1)) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.2->-r requirements.txt (line 1)) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.2->-r requirements.txt (line 1)) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.2->-r requirements.txt (line 1)) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.2->-r requirements.txt (line 1)) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.30.2->-r requirements.txt (line 1))\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m103.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers==4.30.2->-r requirements.txt (line 1))\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m87.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.30.2->-r requirements.txt (line 1)) (4.65.0)\n",
            "Collecting tensorboardX (from tape_proteins==0.5->-r requirements.txt (line 10))\n",
            "  Downloading tensorboardX-2.6.1-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lmdb (from tape_proteins==0.5->-r requirements.txt (line 10))\n",
            "  Downloading lmdb-1.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (299 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting boto3 (from tape_proteins==0.5->-r requirements.txt (line 10))\n",
            "  Downloading boto3-1.26.161-py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.9/135.9 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting biopython (from tape_proteins==0.5->-r requirements.txt (line 10))\n",
            "  Downloading biopython-1.81-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m99.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 3)) (9.0.0)\n",
            "Collecting dill<0.3.7,>=0.3.0 (from datasets->-r requirements.txt (line 3))\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash (from datasets->-r requirements.txt (line 3))\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets->-r requirements.txt (line 3))\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 3)) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 3)) (3.8.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 4)) (2022.7.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 5)) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->-r requirements.txt (line 5)) (3.1.0)\n",
            "Collecting aiofiles (from gradio->-r requirements.txt (line 7))\n",
            "  Downloading aiofiles-23.1.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: altair>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 7)) (4.2.2)\n",
            "Collecting fastapi (from gradio->-r requirements.txt (line 7))\n",
            "  Downloading fastapi-0.98.0-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio->-r requirements.txt (line 7))\n",
            "  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client>=0.2.7 (from gradio->-r requirements.txt (line 7))\n",
            "  Downloading gradio_client-0.2.7-py3-none-any.whl (288 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.4/288.4 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx (from gradio->-r requirements.txt (line 7))\n",
            "  Downloading httpx-0.24.1-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 7)) (3.1.2)\n",
            "Requirement already satisfied: markdown-it-py[linkify]>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 7)) (3.0.0)\n",
            "Requirement already satisfied: markupsafe in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 7)) (2.1.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 7)) (3.7.1)\n",
            "Collecting mdit-py-plugins<=0.3.3 (from gradio->-r requirements.txt (line 7))\n",
            "  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson (from gradio->-r requirements.txt (line 7))\n",
            "  Downloading orjson-3.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (136 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.0/137.0 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 7)) (8.4.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 7)) (1.10.9)\n",
            "Collecting pydub (from gradio->-r requirements.txt (line 7))\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: pygments>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 7)) (2.14.0)\n",
            "Collecting python-multipart (from gradio->-r requirements.txt (line 7))\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version (from gradio->-r requirements.txt (line 7))\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting uvicorn>=0.14.0 (from gradio->-r requirements.txt (line 7))\n",
            "  Downloading uvicorn-0.22.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.0 (from gradio->-r requirements.txt (line 7))\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 8)) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 8)) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 8)) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 8)) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->-r requirements.txt (line 8)) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->-r requirements.txt (line 8)) (16.0.6)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 11)) (5.9.5)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio->-r requirements.txt (line 7)) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio->-r requirements.txt (line 7)) (4.3.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio->-r requirements.txt (line 7)) (0.12.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (1.3.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio->-r requirements.txt (line 7)) (0.1.2)\n",
            "Collecting linkify-it-py<3,>=1 (from markdown-it-py[linkify]>=2.0.0->gradio->-r requirements.txt (line 7))\n",
            "  Downloading linkify_it_py-2.0.2-py3-none-any.whl (19 kB)\n",
            "INFO: pip is looking at multiple versions of mdit-py-plugins to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting mdit-py-plugins<=0.3.3 (from gradio->-r requirements.txt (line 7))\n",
            "  Downloading mdit_py_plugins-0.3.2-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading mdit_py_plugins-0.3.1-py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.5/46.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading mdit_py_plugins-0.3.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading mdit_py_plugins-0.2.8-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading mdit_py_plugins-0.2.7-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading mdit_py_plugins-0.2.6-py3-none-any.whl (39 kB)\n",
            "  Downloading mdit_py_plugins-0.2.5-py3-none-any.whl (39 kB)\n",
            "INFO: pip is looking at multiple versions of mdit-py-plugins to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading mdit_py_plugins-0.2.4-py3-none-any.whl (39 kB)\n",
            "  Downloading mdit_py_plugins-0.2.3-py3-none-any.whl (39 kB)\n",
            "  Downloading mdit_py_plugins-0.2.2-py3-none-any.whl (39 kB)\n",
            "  Downloading mdit_py_plugins-0.2.1-py3-none-any.whl (38 kB)\n",
            "  Downloading mdit_py_plugins-0.2.0-py3-none-any.whl (38 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading mdit_py_plugins-0.1.0-py3-none-any.whl (37 kB)\n",
            "Collecting markdown-it-py[linkify]>=2.0.0 (from gradio->-r requirements.txt (line 7))\n",
            "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->-r requirements.txt (line 4)) (1.16.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30.2->-r requirements.txt (line 1)) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30.2->-r requirements.txt (line 1)) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.30.2->-r requirements.txt (line 1)) (3.4)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio->-r requirements.txt (line 7)) (8.1.3)\n",
            "Collecting h11>=0.8 (from uvicorn>=0.14.0->gradio->-r requirements.txt (line 7))\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting botocore<1.30.0,>=1.29.161 (from boto3->tape_proteins==0.5->-r requirements.txt (line 10))\n",
            "  Downloading botocore-1.29.161-py3-none-any.whl (10.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m116.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3->tape_proteins==0.5->-r requirements.txt (line 10))\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0 (from boto3->tape_proteins==0.5->-r requirements.txt (line 10))\n",
            "  Downloading s3transfer-0.6.1-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting starlette<0.28.0,>=0.27.0 (from fastapi->gradio->-r requirements.txt (line 7))\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpcore<0.18.0,>=0.15.0 (from httpx->gradio->-r requirements.txt (line 7))\n",
            "  Downloading httpcore-0.17.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio->-r requirements.txt (line 7)) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio->-r requirements.txt (line 7)) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio->-r requirements.txt (line 7)) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio->-r requirements.txt (line 7)) (4.40.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio->-r requirements.txt (line 7)) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio->-r requirements.txt (line 7)) (3.1.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r requirements.txt (line 8)) (1.3.0)\n",
            "Collecting protobuf>=4.22.3 (from tensorboardX->tape_proteins==0.5->-r requirements.txt (line 10))\n",
            "  Downloading protobuf-4.23.3-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.5/304.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio->-r requirements.txt (line 7)) (3.7.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio->-r requirements.txt (line 7)) (0.19.3)\n",
            "Collecting uc-micro-py (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio->-r requirements.txt (line 7))\n",
            "  Downloading uc_micro_py-1.0.2-py3-none-any.whl (6.2 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->httpcore<0.18.0,>=0.15.0->httpx->gradio->-r requirements.txt (line 7)) (1.1.1)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4694 sha256=536d86b09117e2266f1fce9ae5ba69529edc6ed3b8185b5276ea94d5c6cbc34b\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/c2/0e/3b9c6845c6a4e35beb90910cc70d9ac9ab5d47402bd62af0df\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: tokenizers, safetensors, pydub, lmdb, ffmpy, xxhash, websockets, uc-micro-py, semantic-version, python-multipart, protobuf, orjson, markdown-it-py, jmespath, h11, dill, biopython, aiofiles, uvicorn, tensorboardX, starlette, multiprocess, mdit-py-plugins, linkify-it-py, huggingface-hub, httpcore, botocore, transformers, s3transfer, httpx, fastapi, gradio-client, datasets, boto3, tape_proteins, gradio, accelerate\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: markdown-it-py\n",
            "    Found existing installation: markdown-it-py 3.0.0\n",
            "    Uninstalling markdown-it-py-3.0.0:\n",
            "      Successfully uninstalled markdown-it-py-3.0.0\n",
            "Successfully installed accelerate-0.20.3 aiofiles-23.1.0 biopython-1.81 boto3-1.26.161 botocore-1.29.161 datasets-2.13.1 dill-0.3.6 fastapi-0.98.0 ffmpy-0.3.0 gradio-3.35.2 gradio-client-0.2.7 h11-0.14.0 httpcore-0.17.2 httpx-0.24.1 huggingface-hub-0.15.1 jmespath-1.0.1 linkify-it-py-2.0.2 lmdb-1.4.1 markdown-it-py-2.2.0 mdit-py-plugins-0.3.3 multiprocess-0.70.14 orjson-3.9.1 protobuf-4.23.3 pydub-0.25.1 python-multipart-0.0.6 s3transfer-0.6.1 safetensors-0.3.1 semantic-version-2.10.0 starlette-0.27.0 tape_proteins-0.5 tensorboardX-2.6.1 tokenizers-0.13.3 transformers-4.30.2 uc-micro-py-1.0.2 uvicorn-0.22.0 websockets-11.0.3 xxhash-3.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "pZ6IkE2a_n6w",
        "outputId": "90f5080a-4a2e-4df7-cb33-3639b5449588",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/project-nlp-update-transformers-lib/SentEval/data/downstream\n",
            "--2023-06-27 07:33:28--  https://huggingface.co/datasets/princeton-nlp/datasets-for-simcse/resolve/main/senteval.tar\n",
            "Resolving huggingface.co (huggingface.co)... 65.9.86.62, 65.9.86.79, 65.9.86.57, ...\n",
            "Connecting to huggingface.co (huggingface.co)|65.9.86.62|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/datasets/princeton-nlp/datasets-for-simcse/bc43c148f7be97471c78fc4255399d3158cb99dfe8f2221999c918338b138c38?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27senteval.tar%3B+filename%3D%22senteval.tar%22%3B&response-content-type=application%2Fx-tar&Expires=1688110408&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL2RhdGFzZXRzL3ByaW5jZXRvbi1ubHAvZGF0YXNldHMtZm9yLXNpbWNzZS9iYzQzYzE0OGY3YmU5NzQ3MWM3OGZjNDI1NTM5OWQzMTU4Y2I5OWRmZThmMjIyMTk5OWM5MTgzMzhiMTM4YzM4P3Jlc3BvbnNlLWNvbnRlbnQtZGlzcG9zaXRpb249KiZyZXNwb25zZS1jb250ZW50LXR5cGU9KiIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY4ODExMDQwOH19fV19&Signature=n9cXJEHfCSUu3tfYvJqxlRdW5A6AWmWnX14Ebx3zdws6LB-ACDMPd-9iEiGugCjoDxNGs2EN0o-E1w9F3FzWmrGeoa3yCRb8WQCjA3gEmz0KwwIyuvJIAGAOKiccI3FPSKxzx6nGZJZBnTxkNlrBpXjJNzTlb2mn2kQk6V2fHCaR6EjjVu87aUxFpNaOKUIcNfbFOZHoeiflg015SqCZ%7E1LfgjCfe7fzhzLEoEJ8y5cLyxTrmlVHbzrnyEMChkjdmqHy8mtlKK2gUAV6hlX8ivs8CLdAYdz4CAKlgG7ufZP-EwENTq7OHeUso31HIrxclDyCgu%7EFDbT7t1PsYYqRQA__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
            "--2023-06-27 07:33:28--  https://cdn-lfs.huggingface.co/datasets/princeton-nlp/datasets-for-simcse/bc43c148f7be97471c78fc4255399d3158cb99dfe8f2221999c918338b138c38?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27senteval.tar%3B+filename%3D%22senteval.tar%22%3B&response-content-type=application%2Fx-tar&Expires=1688110408&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL2RhdGFzZXRzL3ByaW5jZXRvbi1ubHAvZGF0YXNldHMtZm9yLXNpbWNzZS9iYzQzYzE0OGY3YmU5NzQ3MWM3OGZjNDI1NTM5OWQzMTU4Y2I5OWRmZThmMjIyMTk5OWM5MTgzMzhiMTM4YzM4P3Jlc3BvbnNlLWNvbnRlbnQtZGlzcG9zaXRpb249KiZyZXNwb25zZS1jb250ZW50LXR5cGU9KiIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY4ODExMDQwOH19fV19&Signature=n9cXJEHfCSUu3tfYvJqxlRdW5A6AWmWnX14Ebx3zdws6LB-ACDMPd-9iEiGugCjoDxNGs2EN0o-E1w9F3FzWmrGeoa3yCRb8WQCjA3gEmz0KwwIyuvJIAGAOKiccI3FPSKxzx6nGZJZBnTxkNlrBpXjJNzTlb2mn2kQk6V2fHCaR6EjjVu87aUxFpNaOKUIcNfbFOZHoeiflg015SqCZ%7E1LfgjCfe7fzhzLEoEJ8y5cLyxTrmlVHbzrnyEMChkjdmqHy8mtlKK2gUAV6hlX8ivs8CLdAYdz4CAKlgG7ufZP-EwENTq7OHeUso31HIrxclDyCgu%7EFDbT7t1PsYYqRQA__&Key-Pair-Id=KVTP0A1DKRTAX\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 108.156.60.44, 108.156.60.37, 108.156.60.109, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|108.156.60.44|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 89825280 (86M) [application/x-tar]\n",
            "Saving to: ‘senteval.tar’\n",
            "\n",
            "senteval.tar        100%[===================>]  85.66M  32.1MB/s    in 2.7s    \n",
            "\n",
            "2023-06-27 07:33:31 (32.1 MB/s) - ‘senteval.tar’ saved [89825280/89825280]\n",
            "\n",
            "CR/\n",
            "CR/custrev.neg\n",
            "CR/custrev.pos\n",
            "MPQA/\n",
            "MPQA/mpqa.neg\n",
            "MPQA/mpqa.pos\n",
            "MR/\n",
            "MR/rt-polarity.neg\n",
            "MR/rt-polarity.pos\n",
            "MRPC/\n",
            "MRPC/msr_paraphrase_train.txt\n",
            "MRPC/msr_paraphrase_test.txt\n",
            "SICK/\n",
            "SICK/SICK_trial.txt\n",
            "SICK/SICK_train.txt\n",
            "SICK/SICK_test_annotated.txt\n",
            "SNLI/\n",
            "SNLI/s2.test\n",
            "SNLI/s1.train\n",
            "SNLI/s2.train\n",
            "SNLI/labels.dev\n",
            "SNLI/s1.test\n",
            "SNLI/labels.test\n",
            "SNLI/s2.dev\n",
            "SNLI/s1.dev\n",
            "SNLI/labels.train\n",
            "SST/\n",
            "SST/fine/\n",
            "SST/fine/sentiment-test\n",
            "SST/fine/sentiment-train\n",
            "SST/fine/sentiment-dev\n",
            "SST/binary/\n",
            "SST/binary/sentiment-test\n",
            "SST/binary/sentiment-train\n",
            "SST/binary/sentiment-dev\n",
            "STS/\n",
            "STS/STS12-en-test/\n",
            "STS/STS12-en-test/STS.gs.surprise.OnWN.txt\n",
            "STS/STS12-en-test/STS.input.surprise.OnWN.txt\n",
            "STS/STS12-en-test/STS.input.MSRpar.txt\n",
            "STS/STS12-en-test/STS.gs.ALL.txt\n",
            "STS/STS12-en-test/00-readme.txt\n",
            "STS/STS12-en-test/STS.gs.MSRvid.txt\n",
            "STS/STS12-en-test/STS.input.MSRvid.txt\n",
            "STS/STS12-en-test/STS.gs.MSRpar.txt\n",
            "STS/STS12-en-test/STS.input.surprise.SMTnews.txt\n",
            "STS/STS12-en-test/STS.gs.SMTeuroparl.txt\n",
            "STS/STS12-en-test/STS.gs.surprise.SMTnews.txt\n",
            "STS/STS12-en-test/STS.input.SMTeuroparl.txt\n",
            "STS/STS14-en-test/\n",
            "STS/STS14-en-test/STS.input.headlines.txt\n",
            "STS/STS14-en-test/STS.gs.OnWN.txt\n",
            "STS/STS14-en-test/STS.gs.images.txt\n",
            "STS/STS14-en-test/STS.gs.deft-news.txt\n",
            "STS/STS14-en-test/STS.gs.tweet-news.txt\n",
            "STS/STS14-en-test/sts2012-train.tgz\n",
            "STS/STS14-en-test/sts2013-test.tgz\n",
            "STS/STS14-en-test/00-readme.txt\n",
            "STS/STS14-en-test/STS.input.OnWN.txt\n",
            "STS/STS14-en-test/STS.input.deft-news.txt\n",
            "STS/STS14-en-test/sts2012-test.tgz\n",
            "STS/STS14-en-test/STS.input.deft-forum.txt\n",
            "STS/STS14-en-test/STS.output.headlines.txt\n",
            "STS/STS14-en-test/correlation-noconfidence.pl\n",
            "STS/STS14-en-test/STS.gs.headlines.txt\n",
            "STS/STS14-en-test/STS.gs.deft-forum.txt\n",
            "STS/STS14-en-test/STS.input.tweet-news.txt\n",
            "STS/STS14-en-test/STS.input.images.txt\n",
            "STS/STS15-en-test/\n",
            "STS/STS15-en-test/STS.input.headlines.txt\n",
            "STS/STS15-en-test/STS.gs.images.txt\n",
            "STS/STS15-en-test/STS.gs.answers-students.txt\n",
            "STS/STS15-en-test/00-readme.txt\n",
            "STS/STS15-en-test/STS.input.answers-students.txt\n",
            "STS/STS15-en-test/STS.input.answers-forums.LICENSE\n",
            "STS/STS15-en-test/STS.gs.answers-forums.txt\n",
            "STS/STS15-en-test/STS.input.answers-forums.txt\n",
            "STS/STS15-en-test/STS.gs.belief.txt\n",
            "STS/STS15-en-test/correlation-noconfidence.pl\n",
            "STS/STS15-en-test/STS.input.belief.txt\n",
            "STS/STS15-en-test/STS.gs.headlines.txt\n",
            "STS/STS15-en-test/STS.answers-forums.zip\n",
            "STS/STS15-en-test/corebaseline-tokencos.tar.gz\n",
            "STS/STS15-en-test/STS.input.images.txt\n",
            "STS/STS13-en-test/\n",
            "STS/STS13-en-test/STS.input.headlines.txt\n",
            "STS/STS13-en-test/STS.gs.OnWN.txt\n",
            "STS/STS13-en-test/correlation.pl\n",
            "STS/STS13-en-test/STS.input.FNWN.txt\n",
            "STS/STS13-en-test/STS.gs.FNWN.txt\n",
            "STS/STS13-en-test/STS.output.FNWN.txt\n",
            "STS/STS13-en-test/00-readme.txt\n",
            "STS/STS13-en-test/correlation-all.pl\n",
            "STS/STS13-en-test/STS.input.OnWN.txt\n",
            "STS/STS13-en-test/STS.output.headlines.txt\n",
            "STS/STS13-en-test/correct-output.pl\n",
            "STS/STS13-en-test/STS.gs.headlines.txt\n",
            "STS/STS13-en-test/STS.output.SMT.txt\n",
            "STS/STS13-en-test/STS.gs.SMT.txt\n",
            "STS/STS13-en-test/STS.output.OnWN.txt\n",
            "STS/STSBenchmark/\n",
            "STS/STSBenchmark/correlation.pl\n",
            "STS/STSBenchmark/sts-test.csv\n",
            "STS/STSBenchmark/readme.txt\n",
            "STS/STSBenchmark/LICENSE.txt\n",
            "STS/STSBenchmark/sts-train.csv\n",
            "STS/STSBenchmark/sts-dev.csv\n",
            "STS/STS16-en-test/\n",
            "STS/STS16-en-test/STS.input.headlines.txt\n",
            "STS/STS16-en-test/STS.gs.plagiarism.txt\n",
            "STS/STS16-en-test/STS.gs.question-question.txt\n",
            "STS/STS16-en-test/STS.input.question-question.txt\n",
            "STS/STS16-en-test/STS2016.input.headlines.ascii\n",
            "STS/STS16-en-test/README.txt\n",
            "STS/STS16-en-test/STS.gs.answer-answer.txt\n",
            "STS/STS16-en-test/STS2016.input.question-question.ascii\n",
            "STS/STS16-en-test/STS.input.postediting.txt\n",
            "STS/STS16-en-test/STS.input.plagiarism.txt\n",
            "STS/STS16-en-test/STS.gs.postediting.txt\n",
            "STS/STS16-en-test/LICENSE.txt\n",
            "STS/STS16-en-test/STS.input.answer-answer.txt\n",
            "STS/STS16-en-test/correlation-noconfidence.pl\n",
            "STS/STS16-en-test/STS.gs.headlines.txt\n",
            "STS/STS16-en-test/STS2016.input.answer-answer.ascii\n",
            "STS/STS16-en-test/STS2016.input.postediting.ascii\n",
            "STS/STS16-en-test/STS2016.input.plagiarism.ascii\n",
            "SUBJ/\n",
            "SUBJ/subj.subjective\n",
            "SUBJ/subj.objective\n",
            "TREC/\n",
            "TREC/train_5500.label\n",
            "TREC/TREC_10.label\n",
            "/content/project-nlp-update-transformers-lib\n"
          ]
        }
      ],
      "source": [
        "%cd SentEval/data/downstream/\n",
        "!bash download_dataset.sh\n",
        "%cd ../../.."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUw_I-9ylOQk",
        "outputId": "7dfaa828-3f95-4934-950a-4a5cd3d01730"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/project-nlp-update-transformers-lib/data\n",
            "--2023-06-27 07:33:36--  https://huggingface.co/datasets/lpiekarski/datasets-for-simcse/resolve/main/uniprot_for_simcse.txt\n",
            "Resolving huggingface.co (huggingface.co)... 65.9.86.62, 65.9.86.79, 65.9.86.57, ...\n",
            "Connecting to huggingface.co (huggingface.co)|65.9.86.62|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/bc/bc/bcbcbed08034d5ba44d9379d33b0554217896a3a11f0d83bc344698a384335ff/6c67a9c1ed378880f774b130e4c3aaab60a34d1ef2e546f183f485dbfd6a0c74?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27uniprot_for_simcse.txt%3B+filename%3D%22uniprot_for_simcse.txt%22%3B&response-content-type=text%2Fplain&Expires=1688110417&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL3JlcG9zL2JjL2JjL2JjYmNiZWQwODAzNGQ1YmE0NGQ5Mzc5ZDMzYjA1NTQyMTc4OTZhM2ExMWYwZDgzYmMzNDQ2OThhMzg0MzM1ZmYvNmM2N2E5YzFlZDM3ODg4MGY3NzRiMTMwZTRjM2FhYWI2MGEzNGQxZWYyZTU0NmYxODNmNDg1ZGJmZDZhMGM3ND9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE2ODgxMTA0MTd9fX1dfQ__&Signature=QqeXxq-sW1jQcBrjHc7BA90S5Pfs2Ke1Re5KVX1kNPlPiwnNVgmqfB8hGq%7EAgbeI2HFeB49W9nZo4d7ch3zBbNPzMjsnrpngIFPuOsrmZyMBNLEaB-kOOJAJDi7CJnXBIbp-jXfQk7-xOpfp1llbmxhHLE3oxbHmXDmIMFKf693-TCE7s-OSUQDYHEbBa5Cxq2Gb1CYpd-PjZX6m0BoGM4oXOHVHi-P1dTLPJ9C189LX3SSJZdxUovRewysZi5jurPDl52fkTriJiQwkYdSI24xCiQg4Je7dubP7BycXTniuRw0K%7EamjsgQeCKPTHbqUDH66o7jMKQayyi95o-gerA__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
            "--2023-06-27 07:33:36--  https://cdn-lfs.huggingface.co/repos/bc/bc/bcbcbed08034d5ba44d9379d33b0554217896a3a11f0d83bc344698a384335ff/6c67a9c1ed378880f774b130e4c3aaab60a34d1ef2e546f183f485dbfd6a0c74?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27uniprot_for_simcse.txt%3B+filename%3D%22uniprot_for_simcse.txt%22%3B&response-content-type=text%2Fplain&Expires=1688110417&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL3JlcG9zL2JjL2JjL2JjYmNiZWQwODAzNGQ1YmE0NGQ5Mzc5ZDMzYjA1NTQyMTc4OTZhM2ExMWYwZDgzYmMzNDQ2OThhMzg0MzM1ZmYvNmM2N2E5YzFlZDM3ODg4MGY3NzRiMTMwZTRjM2FhYWI2MGEzNGQxZWYyZTU0NmYxODNmNDg1ZGJmZDZhMGM3ND9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE2ODgxMTA0MTd9fX1dfQ__&Signature=QqeXxq-sW1jQcBrjHc7BA90S5Pfs2Ke1Re5KVX1kNPlPiwnNVgmqfB8hGq%7EAgbeI2HFeB49W9nZo4d7ch3zBbNPzMjsnrpngIFPuOsrmZyMBNLEaB-kOOJAJDi7CJnXBIbp-jXfQk7-xOpfp1llbmxhHLE3oxbHmXDmIMFKf693-TCE7s-OSUQDYHEbBa5Cxq2Gb1CYpd-PjZX6m0BoGM4oXOHVHi-P1dTLPJ9C189LX3SSJZdxUovRewysZi5jurPDl52fkTriJiQwkYdSI24xCiQg4Je7dubP7BycXTniuRw0K%7EamjsgQeCKPTHbqUDH66o7jMKQayyi95o-gerA__&Key-Pair-Id=KVTP0A1DKRTAX\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 108.156.60.44, 108.156.60.37, 108.156.60.109, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|108.156.60.44|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 207005927 (197M) [text/plain]\n",
            "Saving to: ‘uniprot_for_simcse.txt’\n",
            "\n",
            "uniprot_for_simcse. 100%[===================>] 197.42M   247MB/s    in 0.8s    \n",
            "\n",
            "2023-06-27 07:33:37 (247 MB/s) - ‘uniprot_for_simcse.txt’ saved [207005927/207005927]\n",
            "\n",
            "/content/project-nlp-update-transformers-lib\n"
          ]
        }
      ],
      "source": [
        "%cd data/\n",
        "!sh download_uniprot.sh\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "looZvvmkhJzu",
        "outputId": "7cc0109f-22d5-402e-9713-e8ca7729a4bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-06-27 08:09:58.296927: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "06/27/2023 08:09:59 - INFO - __main__ -   PyTorch: setting up devices\n",
            "06/27/2023 08:09:59 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1 distributed training: False, 16-bits training: True\n",
            "06/27/2023 08:09:59 - INFO - __main__ -   Training/evaluation parameters OurTrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_backend=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=False,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=None,\n",
            "eval_transfer=False,\n",
            "evaluation_strategy=no,\n",
            "fp16=True,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "greater_is_better=True,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=2e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=-1,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=result/unsup-esm2_t6_8M_UR50D/runs/Jun27_08-09-59_daa24b4b7979,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=stsb_spearman,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=1.0,\n",
            "optim=adamw_hf,\n",
            "optim_args=None,\n",
            "output_dir=result/unsup-esm2_t6_8M_UR50D,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=512,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=result/unsup-esm2_t6_8M_UR50D,\n",
            "save_on_each_node=False,\n",
            "save_safetensors=False,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            "xpu_backend=None,\n",
            ")\n",
            "06/27/2023 08:09:59 - WARNING - datasets.builder -   Found cached dataset text (/content/project-nlp-update-transformers-lib/data/text/default-84dbcaa000a453c0/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2)\n",
            "100% 1/1 [00:00<00:00, 147.52it/s]\n",
            "[INFO|configuration_utils.py:669] 2023-06-27 08:10:00,335 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--esm2_t6_8M_UR50D/snapshots/c731040fcd8d73dceaa04b0a8e6329b345b0f5df/config.json\n",
            "[INFO|configuration_utils.py:725] 2023-06-27 08:10:00,336 >> Model config EsmConfig {\n",
            "  \"_name_or_path\": \"facebook/esm2_t6_8M_UR50D\",\n",
            "  \"architectures\": [\n",
            "    \"EsmForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"emb_layer_norm_before\": false,\n",
            "  \"esmfold_config\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 320,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 1280,\n",
            "  \"is_folding_model\": false,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"mask_token_id\": 32,\n",
            "  \"max_position_embeddings\": 1026,\n",
            "  \"model_type\": \"esm\",\n",
            "  \"num_attention_heads\": 20,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"rotary\",\n",
            "  \"token_dropout\": true,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.30.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_list\": null,\n",
            "  \"vocab_size\": 33\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:1823] 2023-06-27 08:10:00,442 >> loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--facebook--esm2_t6_8M_UR50D/snapshots/c731040fcd8d73dceaa04b0a8e6329b345b0f5df/vocab.txt\n",
            "[INFO|tokenization_utils_base.py:1823] 2023-06-27 08:10:00,443 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1823] 2023-06-27 08:10:00,443 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--facebook--esm2_t6_8M_UR50D/snapshots/c731040fcd8d73dceaa04b0a8e6329b345b0f5df/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:1823] 2023-06-27 08:10:00,443 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--facebook--esm2_t6_8M_UR50D/snapshots/c731040fcd8d73dceaa04b0a8e6329b345b0f5df/tokenizer_config.json\n",
            "[INFO|modeling_utils.py:2578] 2023-06-27 08:10:00,443 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--facebook--esm2_t6_8M_UR50D/snapshots/c731040fcd8d73dceaa04b0a8e6329b345b0f5df/model.safetensors\n",
            "[WARNING|modeling_utils.py:3285] 2023-06-27 08:10:00,593 >> Some weights of the model checkpoint at facebook/esm2_t6_8M_UR50D were not used when initializing EsmForCL: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias']\n",
            "- This IS expected if you are initializing EsmForCL from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing EsmForCL from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[WARNING|modeling_utils.py:3297] 2023-06-27 08:10:00,593 >> Some weights of EsmForCL were not initialized from the model checkpoint at facebook/esm2_t6_8M_UR50D and are newly initialized: ['mlp.dense.bias', 'mlp.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "06/27/2023 08:10:00 - WARNING - datasets.arrow_dataset -   Loading cached processed dataset at /content/project-nlp-update-transformers-lib/data/text/default-84dbcaa000a453c0/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2/cache-0d1dab72696078f7.arrow\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "06/27/2023 08:10:03 - INFO - simcse.trainers -   ***** Running training *****\n",
            "06/27/2023 08:10:03 - INFO - simcse.trainers -     Num examples = 569516\n",
            "06/27/2023 08:10:03 - INFO - simcse.trainers -     Num Epochs = 1\n",
            "06/27/2023 08:10:03 - INFO - simcse.trainers -     Instantaneous batch size per device = 512\n",
            "06/27/2023 08:10:03 - INFO - simcse.trainers -     Total train batch size (w. parallel, distributed & accumulation) = 512\n",
            "06/27/2023 08:10:03 - INFO - simcse.trainers -     Gradient Accumulation steps = 1\n",
            "06/27/2023 08:10:03 - INFO - simcse.trainers -     Total optimization steps = 1113\n",
            "{'loss': 0.0916, 'learning_rate': 1.101527403414196e-05, 'epoch': 0.45}\n",
            " 45% 500/1113 [07:29<09:50,  1.04it/s][INFO|trainer.py:2926] 2023-06-27 08:17:32,791 >> Saving model checkpoint to result/unsup-esm2_t6_8M_UR50D/checkpoint-500\n",
            "[INFO|configuration_utils.py:458] 2023-06-27 08:17:32,792 >> Configuration saved in result/unsup-esm2_t6_8M_UR50D/checkpoint-500/config.json\n",
            "[INFO|modeling_utils.py:1853] 2023-06-27 08:17:32,866 >> Model weights saved in result/unsup-esm2_t6_8M_UR50D/checkpoint-500/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2194] 2023-06-27 08:17:32,867 >> tokenizer config file saved in result/unsup-esm2_t6_8M_UR50D/checkpoint-500/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2201] 2023-06-27 08:17:32,867 >> Special tokens file saved in result/unsup-esm2_t6_8M_UR50D/checkpoint-500/special_tokens_map.json\n",
            "{'loss': 0.0023, 'learning_rate': 2.0305480682839176e-06, 'epoch': 0.9}\n",
            " 90% 1000/1113 [15:03<01:41,  1.12it/s][INFO|trainer.py:2926] 2023-06-27 08:25:06,640 >> Saving model checkpoint to result/unsup-esm2_t6_8M_UR50D/checkpoint-1000\n",
            "[INFO|configuration_utils.py:458] 2023-06-27 08:25:06,641 >> Configuration saved in result/unsup-esm2_t6_8M_UR50D/checkpoint-1000/config.json\n",
            "[INFO|modeling_utils.py:1853] 2023-06-27 08:25:06,689 >> Model weights saved in result/unsup-esm2_t6_8M_UR50D/checkpoint-1000/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2194] 2023-06-27 08:25:06,689 >> tokenizer config file saved in result/unsup-esm2_t6_8M_UR50D/checkpoint-1000/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2201] 2023-06-27 08:25:06,690 >> Special tokens file saved in result/unsup-esm2_t6_8M_UR50D/checkpoint-1000/special_tokens_map.json\n",
            "100% 1113/1113 [16:45<00:00,  1.38it/s]06/27/2023 08:26:48 - INFO - simcse.trainers -   \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 1005.5218, 'train_samples_per_second': 1.107, 'epoch': 1.0}\n",
            "100% 1113/1113 [16:45<00:00,  1.11it/s]\n",
            "[INFO|trainer.py:2926] 2023-06-27 08:26:48,826 >> Saving model checkpoint to result/unsup-esm2_t6_8M_UR50D\n",
            "[INFO|configuration_utils.py:458] 2023-06-27 08:26:48,827 >> Configuration saved in result/unsup-esm2_t6_8M_UR50D/config.json\n",
            "[INFO|modeling_utils.py:1853] 2023-06-27 08:26:48,877 >> Model weights saved in result/unsup-esm2_t6_8M_UR50D/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2194] 2023-06-27 08:26:48,877 >> tokenizer config file saved in result/unsup-esm2_t6_8M_UR50D/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2201] 2023-06-27 08:26:48,878 >> Special tokens file saved in result/unsup-esm2_t6_8M_UR50D/special_tokens_map.json\n",
            "06/27/2023 08:26:48 - INFO - __main__ -   ***** Train results *****\n",
            "06/27/2023 08:26:48 - INFO - __main__ -     epoch = 1.0\n",
            "06/27/2023 08:26:48 - INFO - __main__ -     train_runtime = 1005.5218\n",
            "06/27/2023 08:26:48 - INFO - __main__ -     train_samples_per_second = 1.107\n"
          ]
        }
      ],
      "source": [
        "!python train.py \\\n",
        "--model_name_or_path facebook/esm2_t6_8M_UR50D \\\n",
        "--train_file data/uniprot_for_simcse.txt \\\n",
        "--output_dir result/unsup-esm2_t6_8M_UR50D \\\n",
        "--num_train_epochs 1 \\\n",
        "--per_device_train_batch_size 512 \\\n",
        "--learning_rate 2e-5 \\\n",
        "--max_seq_length  32 \\\n",
        "--metric_for_best_model stsb_spearman \\\n",
        "--pooler_type cls \\\n",
        "--mlp_only_train \\\n",
        "--overwrite_output_dir \\\n",
        "--temp 0.05 \\\n",
        "--do_train \\\n",
        "--fp16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfMlJDHM6P54"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}