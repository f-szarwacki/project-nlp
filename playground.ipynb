{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pass"
      ],
      "metadata": {
        "id": "HQv_2KFChkpp"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XBMFF4u2Z_VE"
      },
      "outputs": [],
      "source": [
        "!unzip project-nlp-main.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd project-nlp-main/"
      ],
      "metadata": {
        "id": "yaBZpd20bOiN",
        "outputId": "27ef0f7b-2b40-4a91-f3e8-b9241e14b6f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "project-nlp-main  project-nlp-main.zip\tsample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requirements.txt"
      ],
      "metadata": {
        "id": "9Rpcx-LFfxCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd data/\n",
        "!sh download_uniprot.sh\n",
        "%cd .."
      ],
      "metadata": {
        "id": "aUw_I-9ylOQk",
        "outputId": "8024c7da-7c05-46e8-aba0-2c49c41c96f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-26 12:02:09--  https://huggingface.co/datasets/lpiekarski/datasets-for-simcse/resolve/main/uniprot_for_simcse.txt\n",
            "Resolving huggingface.co (huggingface.co)... 18.172.134.4, 18.172.134.88, 18.172.134.124, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.172.134.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/bc/bc/bcbcbed08034d5ba44d9379d33b0554217896a3a11f0d83bc344698a384335ff/6c67a9c1ed378880f774b130e4c3aaab60a34d1ef2e546f183f485dbfd6a0c74?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27uniprot_for_simcse.txt%3B+filename%3D%22uniprot_for_simcse.txt%22%3B&response-content-type=text%2Fplain&Expires=1688040130&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL3JlcG9zL2JjL2JjL2JjYmNiZWQwODAzNGQ1YmE0NGQ5Mzc5ZDMzYjA1NTQyMTc4OTZhM2ExMWYwZDgzYmMzNDQ2OThhMzg0MzM1ZmYvNmM2N2E5YzFlZDM3ODg4MGY3NzRiMTMwZTRjM2FhYWI2MGEzNGQxZWYyZTU0NmYxODNmNDg1ZGJmZDZhMGM3ND9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE2ODgwNDAxMzB9fX1dfQ__&Signature=ZiB5nNb--rjhxLjNGwvoQrfuunckPiukJvdRIsI3WeclbDtnGMeyTY7KDkpSshaCqd6Pj7CJUXlCY0XxlMBpKSERqalCsgJEzhHXjTYhtd5DuJY0HCeHrv5wQysxCqr7Z6RJKrj1I33VDG8E9zjqZ9f13-7NXxJ68xCX1SdMKYYPpyHVlGaGVqi4mRrHockRkPqRw6jTg-ydnrghlSbaYC9sJmDHFhr%7Ekp5yeGxPASj7gxXUO87DHMVhSEyss%7EeBwigPzSGSii7zpVH1JRqxR0NBobgmwPD4nf0zHIOqm1zELEzUaCX2CLSpuCGbu%7E0X47wjQi3Izb3D5P5oO60Sfw__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
            "--2023-06-26 12:02:09--  https://cdn-lfs.huggingface.co/repos/bc/bc/bcbcbed08034d5ba44d9379d33b0554217896a3a11f0d83bc344698a384335ff/6c67a9c1ed378880f774b130e4c3aaab60a34d1ef2e546f183f485dbfd6a0c74?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27uniprot_for_simcse.txt%3B+filename%3D%22uniprot_for_simcse.txt%22%3B&response-content-type=text%2Fplain&Expires=1688040130&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL3JlcG9zL2JjL2JjL2JjYmNiZWQwODAzNGQ1YmE0NGQ5Mzc5ZDMzYjA1NTQyMTc4OTZhM2ExMWYwZDgzYmMzNDQ2OThhMzg0MzM1ZmYvNmM2N2E5YzFlZDM3ODg4MGY3NzRiMTMwZTRjM2FhYWI2MGEzNGQxZWYyZTU0NmYxODNmNDg1ZGJmZDZhMGM3ND9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE2ODgwNDAxMzB9fX1dfQ__&Signature=ZiB5nNb--rjhxLjNGwvoQrfuunckPiukJvdRIsI3WeclbDtnGMeyTY7KDkpSshaCqd6Pj7CJUXlCY0XxlMBpKSERqalCsgJEzhHXjTYhtd5DuJY0HCeHrv5wQysxCqr7Z6RJKrj1I33VDG8E9zjqZ9f13-7NXxJ68xCX1SdMKYYPpyHVlGaGVqi4mRrHockRkPqRw6jTg-ydnrghlSbaYC9sJmDHFhr%7Ekp5yeGxPASj7gxXUO87DHMVhSEyss%7EeBwigPzSGSii7zpVH1JRqxR0NBobgmwPD4nf0zHIOqm1zELEzUaCX2CLSpuCGbu%7E0X47wjQi3Izb3D5P5oO60Sfw__&Key-Pair-Id=KVTP0A1DKRTAX\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.154.185.26, 18.154.185.94, 18.154.185.64, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.154.185.26|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 207005927 (197M) [text/plain]\n",
            "Saving to: ‘uniprot_for_simcse.txt’\n",
            "\n",
            "uniprot_for_simcse. 100%[===================>] 197.42M  50.0MB/s    in 3.9s    \n",
            "\n",
            "2023-06-26 12:02:14 (50.0 MB/s) - ‘uniprot_for_simcse.txt’ saved [207005927/207005927]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py \\\n",
        "--model_name_or_path facebook/esm2_t6_8M_UR50D \\\n",
        "--train_file data/uniprot_for_simcse.txt \\\n",
        "--output_dir result/unsup-esm2_t6_8M_UR50D \\\n",
        "--num_train_epochs 4 \\\n",
        "--per_device_train_batch_size 64 \\\n",
        "--learning_rate 2e-5 \\\n",
        "--max_seq_length  32 \\\n",
        "--evaluation_strategy steps \\\n",
        "--metric_for_best_model stsb_spearman \\\n",
        "--load_best_model_at_end \\\n",
        "--eval_steps 125 \\\n",
        "--pooler_type cls \\\n",
        "--mlp_only_train \\\n",
        "--overwrite_output_dir \\\n",
        "--temp 0.05 \\\n",
        "--do_train \\\n",
        "--fp16"
      ],
      "metadata": {
        "id": "looZvvmkhJzu",
        "outputId": "354839d5-ef9a-4339-fcf6-5a7c91fac2c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-06-26 12:04:42.345327: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "06/26/2023 12:04:43 - INFO - __main__ -   PyTorch: setting up devices\n",
            "06/26/2023 12:04:43 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1 distributed training: False, 16-bits training: True\n",
            "06/26/2023 12:04:43 - INFO - __main__ -   Training/evaluation parameters OurTrainingArguments(\n",
            "_n_gpu=1,\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_pin_memory=True,\n",
            "ddp_backend=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_steps=125,\n",
            "eval_transfer=False,\n",
            "evaluation_strategy=steps,\n",
            "fp16=True,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "greater_is_better=True,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=False,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_inputs_for_metrics=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=2e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=-1,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=result/unsup-esm2_t6_8M_UR50D/runs/Jun26_12-04-43_22d0feb14df9,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_type=linear,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=stsb_spearman,\n",
            "mp_parameters=,\n",
            "no_cuda=False,\n",
            "num_train_epochs=4.0,\n",
            "optim=adamw_hf,\n",
            "optim_args=None,\n",
            "output_dir=result/unsup-esm2_t6_8M_UR50D,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=64,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard'],\n",
            "resume_from_checkpoint=None,\n",
            "run_name=result/unsup-esm2_t6_8M_UR50D,\n",
            "save_on_each_node=False,\n",
            "save_safetensors=False,\n",
            "save_steps=500,\n",
            "save_strategy=steps,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "sharded_ddp=[],\n",
            "skip_memory_metrics=True,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            "xpu_backend=None,\n",
            ")\n",
            "Downloading and preparing dataset text/default to /content/project-nlp-main/data/text/default-b254495663a4aca9/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2...\n",
            "Downloading data files: 100% 1/1 [00:00<00:00, 7570.95it/s]\n",
            "Extracting data files: 100% 1/1 [00:00<00:00, 994.62it/s]\n",
            "Dataset text downloaded and prepared to /content/project-nlp-main/data/text/default-b254495663a4aca9/0.0.0/cb1e9bd71a82ad27976be3b12b407850fe2837d80c22c5e03a28949843a8ace2. Subsequent calls will reuse this data.\n",
            "100% 1/1 [00:00<00:00, 95.64it/s]\n",
            "Downloading (…)lve/main/config.json: 100% 775/775 [00:00<00:00, 4.17MB/s]\n",
            "[INFO|configuration_utils.py:669] 2023-06-26 12:04:47,504 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--esm2_t6_8M_UR50D/snapshots/c731040fcd8d73dceaa04b0a8e6329b345b0f5df/config.json\n",
            "[INFO|configuration_utils.py:725] 2023-06-26 12:04:47,505 >> Model config EsmConfig {\n",
            "  \"_name_or_path\": \"facebook/esm2_t6_8M_UR50D\",\n",
            "  \"architectures\": [\n",
            "    \"EsmForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.0,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"emb_layer_norm_before\": false,\n",
            "  \"esmfold_config\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.0,\n",
            "  \"hidden_size\": 320,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 1280,\n",
            "  \"is_folding_model\": false,\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"mask_token_id\": 32,\n",
            "  \"max_position_embeddings\": 1026,\n",
            "  \"model_type\": \"esm\",\n",
            "  \"num_attention_heads\": 20,\n",
            "  \"num_hidden_layers\": 6,\n",
            "  \"pad_token_id\": 1,\n",
            "  \"position_embedding_type\": \"rotary\",\n",
            "  \"token_dropout\": true,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.30.2\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_list\": null,\n",
            "  \"vocab_size\": 33\n",
            "}\n",
            "\n",
            "Downloading (…)okenizer_config.json: 100% 95.0/95.0 [00:00<00:00, 872kB/s]\n",
            "Downloading (…)solve/main/vocab.txt: 100% 93.0/93.0 [00:00<00:00, 821kB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100% 125/125 [00:00<00:00, 969kB/s]\n",
            "[INFO|tokenization_utils_base.py:1823] 2023-06-26 12:04:47,831 >> loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--facebook--esm2_t6_8M_UR50D/snapshots/c731040fcd8d73dceaa04b0a8e6329b345b0f5df/vocab.txt\n",
            "[INFO|tokenization_utils_base.py:1823] 2023-06-26 12:04:47,831 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1823] 2023-06-26 12:04:47,831 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--facebook--esm2_t6_8M_UR50D/snapshots/c731040fcd8d73dceaa04b0a8e6329b345b0f5df/special_tokens_map.json\n",
            "[INFO|tokenization_utils_base.py:1823] 2023-06-26 12:04:47,831 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--facebook--esm2_t6_8M_UR50D/snapshots/c731040fcd8d73dceaa04b0a8e6329b345b0f5df/tokenizer_config.json\n",
            "Downloading model.safetensors: 100% 31.4M/31.4M [00:00<00:00, 83.5MB/s]\n",
            "[INFO|modeling_utils.py:2578] 2023-06-26 12:04:48,316 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--facebook--esm2_t6_8M_UR50D/snapshots/c731040fcd8d73dceaa04b0a8e6329b345b0f5df/model.safetensors\n",
            "[WARNING|modeling_utils.py:3285] 2023-06-26 12:04:48,517 >> Some weights of the model checkpoint at facebook/esm2_t6_8M_UR50D were not used when initializing EsmForCL: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing EsmForCL from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing EsmForCL from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[WARNING|modeling_utils.py:3297] 2023-06-26 12:04:48,517 >> Some weights of EsmForCL were not initialized from the model checkpoint at facebook/esm2_t6_8M_UR50D and are newly initialized: ['mlp.dense.bias', 'mlp.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Map:  27% 153000/569516 [06:02<12:00, 577.99 examples/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GTYDab4ok5Ei"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
